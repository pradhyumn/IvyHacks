{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment Variable (with dotenv)\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "import openai\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/anushka/.local/lib/python3.11/site-packages/mylinear_cpp-0.0.0-py3.11-macosx-13.0-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiconfig import AIConfigRuntime\n",
    "import aiconfig_extension_gemini\n",
    "# Load the config you just created\n",
    "from aiconfig import CallbackManager, InferenceOptions\n",
    "aiconfig = AIConfigRuntime.load(\"interview.aiconfig.json\")\n",
    "\n",
    "aiconfig.callback_manager = CallbackManager([]) # Skip Logging, Google Colab forwards logs to stdout\n",
    "inference_options = InferenceOptions(stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(human_prefix = \"Question:\",ai_prefix = \"Candidate Response:\",k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini output: **Emotional Insight**\n",
      "\n",
      "* The candidate seems confident and well-prepared for the interview.\n",
      "* They maintain a positive and enthusiastic demeanor throughout their response.\n",
      "* Their body language is relaxed and open, and they make good eye contact with the interviewer.\n",
      "\n",
      "**Content Accuracy**\n",
      "\n",
      "* The candidate's response is generally accurate and relevant to the question.\n",
      "* They provide a concise overview of their education, work experience, and research interests.\n",
      "* However, they could have provided more specific examples of their work experience and how it relates to the role they are interviewing for.\n",
      "\n",
      "**Clarity and Structure**\n",
      "\n",
      "* The candidate's response is well-organized and easy to follow.\n",
      "* They use clear and concise language, and they provide a logical flow of ideas.\n",
      "\n",
      "**Sufficiency and Depth**\n",
      "\n",
      "* The candidate's response provides a good overview of their qualifications and experience.\n",
      "* However, they could have provided more in-depth information about their skills and accomplishments.\n",
      "\n",
      "**Overall, the candidate's response is well-delivered and provides a positive impression. However, they could have provided more specific examples of their work experience and how it relates to the role they are interviewing for.**\n"
     ]
    }
   ],
   "source": [
    "a=aiconfig.get_parameters(\"response_feedback\")\n",
    "candidate_response=a['candidate_response']\n",
    "candidate_emotion_analysis=a['candidate_emotion_analysis']\n",
    "aiconfig.delete_output(\"response_feedback\")\n",
    "#await aiconfig.run(\"response_feedback\", params={\"candidate_response\": candidate_response,\"candidate_emotion_analysis\":candidate_emotion_analysis})\n",
    "await aiconfig.run(\"response_feedback\")\n",
    "output_text = aiconfig.get_output_text(\"response_feedback\")\n",
    "print(f'Gemini output: {output_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs={\"inputs\":a['question']}\n",
    "outputs={\"outputs\":a['candidate_response']}\n",
    "memory.save_context(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question:: tell me about yourself.\\nCandidate Response:: Hi, I am Anushka. I am MSCS student at Umass Amherst.I have 2 years of experience as ML Engineer in India. I have worked at a Automated Product cataloging startup for 2 years and then at PwC as an ML associate for an year. Most of my workex has focused on Text generation, finetunig transformer models, Retrieval Augmented Generation based Pipeline over Audit data and a little weak supervision work. My interests currently include NLP and Information retrieval systems. I am also working at the BIONLP lab at Umass where I am working on LLM Alignment and Self rewarding LLMs in medical domain.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_history=memory.load_memory_variables({})['history']\n",
    "interview_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExecuteResult(output_type='execute_result', execution_count=0, data='**Next Question:**\\n\\n\"Anushka, in your previous role at PwC, you mentioned working on a prototype of the Audit Assistant Platform using various NLP techniques. Can you describe the specific challenges you faced during the development process and how you overcame them? This will help us understand your problem-solving abilities and how you approach technical complexities in your work.\"', mime_type=None, metadata={'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE'}]})]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiconfig.delete_output(\"QG_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidate_profile': 'Anushka Yadav is a highly skilled computer science graduate student at the University of Massachusetts Amherst, with a strong background in machine learning, big data, and information retrieval. She holds a B.Tech in Computer Science and Engineering from the Indian Institute of Information Technology, Nagpur, with a CGPA of 8.21/10.\\n\\nWork Experience:\\n- Machine Learning Associate 2 at PwC AC Bangalore (US Advisory), where she developed a prototype of the Audit Assistant Platform using multi-source document QnA system, semantic vector research, and LLMs. She also integrated a Langchain-based Chatbot and researched weak supervision in NLP using GPT-3.\\n- Machine Learning Engineer at Text Mercato Solutions Private Limited, where she handled the product development lifecycle of an Automatic Product description generator, optimized the Quality Check process, and enhanced the accuracy of an AI Data Sourcing Tool.\\n- Deep Learning Intern at Text Mercato Solutions Private Limited, working on POCs of AI-based Data Sourcing Tool and Description Generation tool.\\n- Research Intern at Visvesvaraya National Institute of Technology, researching Agent-Based Trading in Stock Market using Reinforcement Learning.\\n\\nProjects:\\n- Virtual Try On: Developed a virtual trial room application for Retail Space using GANs and computer vision.\\n- Paraphrase Generation & Identification: Worked on paraphrase generation using T5 transformer and optimized RoBERTa for paraphrase identification using Population-Based Training.\\n\\nPublications:\\n- Co-authored a paper titled \"A Q-learning agent for automated trading in equity stock markets\" in Expert Systems with Applications.\\n\\nTechnical Skills:\\n- Programming Languages: Python, C, C++, Java(Core)',\n",
       " 'job_description': 'Lab Summary: As an NLP Intern you will primarily focus on building the NLU platform for Bixby by working with Machine Learning Experts, Lab Leaders and Linguistic Experts, brainstorming novel ideas, researching, building POCs and proposing solutions that cater to the broader business needs. You will work with a small and nimble team to help design machine learning models, data pipelines, integrate into and maintain production systems and analyze key metrics for decision makers to provide insights that will be beneficial to Bixby consumers.\\n\\nPosition Summary: As an NLP Intern you will primarily focus on building the NLU platform for Bixby by working with Machine Learning Experts, Lab Leaders and Linguistic Experts, brainstorming novel ideas, researching, building POCs and proposing solutions that cater to the broader business needs. You will work with a small and nimble team to help design machine learning models, data pipelines, integrate into and maintain production systems and analyze key metrics for decision makers to provide insights that will be beneficial to Bixby consumers.\\n\\nPosition Responsibilities\\n\\nAs an NLP intern, you will research, prototype, develop, deploy and scale innovative ML/NLP solutions in collaboration with Linguistic Experts and Product Management teams\\nYou will develop predictive models on large-scale datasets to address various business problems leveraging advanced statistical modeling, machine learning, or data mining techniques\\nSet up processes to monitor and continually improve efficiency and performance of models\\nSoftware development including algorithm implementation, optimization, performance profiling, integration to production systems, testing and documentation\\nProgram primarily in Python using efficient algorithms and software design patterns\\n\\nRequired Skills\\n\\nPursuing a Master’s degree or Ph.D. in relevant field\\nRelevant experience in Natural Language Understanding, Intent Classification and Slot Filling, Dialogue Management, Question Answering, Text Classification, Information Retrieval, or Knowledge Extraction\\nExperience with building end-to-end systems based on machine learning or deep learning methods\\nStrong understanding of computer science fundamentals such as algorithms, data structures and run-time analysis\\nProficiency in Python\\nExperience in tuning prompts for Large Language Models\\nExperience in training Large Language Models (pretraining, fine-tuning, parameter efficient training)\\nExperience in serving and optimizing models latency and memory footprint through techniques like quantization or custom kernel application\\nExperience with deep learning architectures such as LSTMs, Transformers, Tree-LSTMs, Graph Neural Networks, etc.\\nExperience with cutting-edge deep learning–based NLP models such as ELMo, BERT, OpenAI GPT-2/3, BART, BigBird, ERNIE, etc.\\nExperience with deep learning NLP toolkits such as huggingface, spacy, etc.\\nExperience with deep learning frameworks like TensorFlow, PyTorch, JAX and libraries like Hugging Face transformers, Deep Graph Library, DGL-KE, etc.\\nAble to solve real–world problems using cutting–edge ideas and independent research\\nA willingness to learn and remain agile in a dynamic environment\\nAnalytical and problem-solving skills for design, creation and testing of custom software\\nExtensive experience with software prototyping or designing experimental software\\nAdept at adapting academic ideas and theoretical algorithms into a production system',\n",
       " 'time_left': '38 minutes'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiconfig.get_parameters(\"QG_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiconfig.get_prompt(\"QG_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini output: **Next Question:**\n",
      "\n",
      "\"Given your research experience in LLM alignment and self-rewarding LLMs in the medical domain, could you elaborate on your understanding of the challenges involved in deploying and evaluating these models in a clinical setting? Specifically, how do you ensure responsible and ethical use of such models in healthcare?\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This time, let's also add a callback manager to log more detailed events\n",
    "aiconfig.callback_manager = CallbackManager([])\n",
    "\n",
    "await aiconfig.run(\"QG_prompt\", params={'interview_history': interview_history},run_with_dependencies=True,options=inference_options)\n",
    "output_text = aiconfig.get_output_text(\"QG_prompt\")\n",
    "print(f'Gemini output: {output_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidate_emotion_analysis': 'The candidate looks confident and enthusiastic with a smiling face.',\n",
       " 'candidate_response': 'Hi, I am Anushka. I am MSCS student at Umass Amherst.I have 2 years of experience as ML Engineer in India. I have worked at a Automated Product cataloging startup for 2 years and then at PwC as an ML associate for an year. Most of my workex has focused on Text generation, finetunig transformer models, Retrieval Augmented Generation based Pipeline over Audit data and a little weak supervision work. My interests currently include NLP and Information retrieval systems. I am also working at the BIONLP lab at Umass where I am working on LLM Alignment and Self rewarding LLMs in medical domain.',\n",
       " 'question': 'tell me about yourself.'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyse_and_generate(aiconfig,candidate_emotion_analysis,candidate_response,question,time_left):\n",
    "    aiconfig.delete_output(\"response_feedback\")\n",
    "    a=aiconfig.get_parameters(\"response_feedback\")\n",
    "    await aiconfig.run(\"response_feedback\", params={\"candidate_response\": candidate_response,\"candidate_emotion_analysis\":candidate_emotion_analysis})\n",
    "    response_feedback = aiconfig.get_output_text(\"response_feedback\")\n",
    "    #adding current q and r to memory\n",
    "    inputs={\"inputs\":a['question']}\n",
    "    outputs={\"outputs\":a['candidate_response']}\n",
    "    memory.save_context(inputs, outputs)\n",
    "    interview_history=memory.load_memory_variables({})['history']\n",
    "    \n",
    "    aiconfig.delete_output(\"QG_prompt\")\n",
    "    await aiconfig.run(\"QG_prompt\", params={'interview_history': interview_history},run_with_dependencies=True,options=inference_options)\n",
    "    question_res = aiconfig.get_output_text(\"QG_prompt\")\n",
    "    \n",
    "    return question_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sysds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
